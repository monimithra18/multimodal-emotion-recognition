{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f1004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import string\n",
    "import demoji\n",
    "import os.path\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import load_model, Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6022da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Loading the tokenizer (for example)\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    loaded_tokenizer = pickle.load(handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c07844b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\python\\python36\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: importlib-resources in d:\\python\\python36\\lib\\site-packages (from demoji) (3.3.1)\n",
      "Requirement already satisfied: zipp>=0.4 in d:\\python\\python36\\lib\\site-packages (from importlib-resources->demoji) (3.6.0)\n",
      "Installing collected packages: demoji\n",
      "Successfully installed demoji-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for setuptools: [Errno 2] No such file or directory: 'd:\\\\python\\\\python36\\\\lib\\\\site-packages\\\\setuptools-59.6.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for pyocr: [Errno 2] No such file or directory: 'd:\\\\python\\\\python36\\\\lib\\\\site-packages\\\\pyocr-0.8.3.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for keras-applications: [Errno 2] No such file or directory: 'd:\\\\python\\\\python36\\\\lib\\\\site-packages\\\\Keras_Applications-1.0.8.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for html2text: [Errno 2] No such file or directory: 'd:\\\\python\\\\python36\\\\lib\\\\site-packages\\\\html2text-2020.1.16.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -pencv-python (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (d:\\python\\python36\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8fb40e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "max_words = 30\n",
    "# Download the demoji library data\n",
    "demoji.download_codes()\n",
    "\n",
    "# Define a function to clean the text data\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove retweet tags and mentions\n",
    "    text = re.sub('(RT|via)((?:\\\\b\\\\W*@\\\\w+)+)', ' ', text)\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = demoji.replace(text, '')\n",
    "    \n",
    "    # Remove special characters and symbols\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert all text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # Remove any remaining noise\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b589a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open(r\"model.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(r\"model_weights.h5\")\n",
    " \n",
    "def preprocess_text(comment):\n",
    "    # Add the same preprocessing steps you applied to the training data\n",
    "    clean_comment = clean_text(comment)\n",
    "    tokenized_comment = loaded_tokenizer.texts_to_sequences([clean_comment])\n",
    "    padded_comment = sequence.pad_sequences(tokenized_comment, maxlen=max_words)\n",
    "    return padded_comment\n",
    "\n",
    "def make_prediction(comment, model):\n",
    "    preprocessed_comment = preprocess_text(comment)\n",
    "    prediction = np.argmax(loaded_model.predict(preprocessed_comment), axis=1)\n",
    "    if prediction == 0:\n",
    "        return \"Negative\"\n",
    "    elif prediction == 1:\n",
    "        return \"Neutral\"\n",
    "    elif prediction == 2:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fadad0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(\"Not Feeling well very bad day\",loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be461165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
